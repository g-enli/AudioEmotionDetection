{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model Test ve Değerlendirme\n",
    "Bu notebook, eğitim aşamasında kaydedilen **RNN (LSTM)** modelini yükleyerek, ayrılmış olan **test verileri** üzerinde performansını ölçer.\n",
    "\n",
    "Amaç, modelin daha önce hiç görmediği veriler üzerindeki genelleme yeteneğini ve nihai başarımını doğrulamaktır. İşlem adımları:\n",
    "1. Gerekli kütüphaneler yüklenir.\n",
    "2. Değerlendirme fonksiyonu tanımlanır.\n",
    "3. Veri seti (`CREMA-D` veya `EMO-DB`) için kaydedilmiş model ve test verileri (`.pth`, `.npy`, `.pkl`) yüklenir.\n",
    "4. Modelin test performansı (Accuracy, F1-Score, Precision, Recall, Confusion Matrix) hesaplanır ve görselleştirilir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Kütüphanelerin Yüklenmesi ve Ayarlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# Google Drive bağlantısı (lokal ortamda kapatılmalı)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# os.chdir('/content/drive/MyDrive/AudioEmotionDetection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RNN Modeli Tanımlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2, num_classes=6):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.3)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Veri Seti Sınıfı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Değerlendirme Fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, model_name, dataset_name, le, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"Modeli test verisi üzerinde değerlendirir ve sonuçları görselleştirir.\"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    test_preds, test_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "            test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Metrikleri hesapla\n",
    "    accuracy = accuracy_score(test_labels, test_preds)\n",
    "    f1 = f1_score(test_labels, test_preds, average='weighted')\n",
    "    precision = precision_score(test_labels, test_preds, average='weighted')\n",
    "    recall = recall_score(test_labels, test_preds, average='weighted')\n",
    "    cm = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "    # Sonuçları yazdır\n",
    "    print(f'--- {model_name} ({dataset_name}) TEST SONUÇLARI ---')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1-Score: {f1:.4f}')\n",
    "    print(f'\\nSınıf Bazlı Performans:\\n{classification_report(test_labels, test_preds, target_names=le.classes_)}')\n",
    "\n",
    "    # Karışıklık Matrisini çizdir\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(f'{model_name} ({dataset_name}) Test Karışıklık Matrisi')\n",
    "    plt.xlabel('Tahmin Edilen')\n",
    "    plt.ylabel('Gerçek')\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Verisi ile Modelin Değerlendirilmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['CREMA-D']  # EMO-DB eklenebilir\n",
    "test_results = []\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    print(f\"\\n{'='*20} {dataset_name} TEST AŞAMASI {'='*20}\")\n",
    "    try:\n",
    "        # Kaydedilmiş verileri ve modeli yükle\n",
    "        X_test = np.load(f'X_test_{dataset_name}.npy')\n",
    "        y_test = np.load(f'y_test_{dataset_name}.npy')\n",
    "        le = joblib.load(f'label_encoder_{dataset_name}.pkl')\n",
    "\n",
    "        # RNN modelini başlat\n",
    "        model = RNNModel(input_size=X_test.shape[1], hidden_size=64, num_layers=2, num_classes=len(le.classes_))\n",
    "        model.load_state_dict(torch.load(f'rnn_model_{dataset_name}.pth'))\n",
    "\n",
    "        # Test veri setini hazırla\n",
    "        test_dataset = AudioDataset(X_test, y_test)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "        # Modeli değerlendir\n",
    "        rnn_acc, rnn_f1, rnn_pre, rnn_rec = evaluate_model(model, test_loader, 'RNN', dataset_name, le)\n",
    "\n",
    "        # Sonuçları kaydet\n",
    "        test_results.append({\n",
    "            'Model': 'RNN',\n",
    "            'Accuracy': rnn_acc,\n",
    "            'F1-Score': rnn_f1,\n",
    "            'Precision': rnn_pre,\n",
    "            'Recall': rnn_rec,\n",
    "            'Dataset': dataset_name\n",
    "        })\n",
    "    except FileNotFoundError as e:\n",
    "        print(f'HATA: {dataset_name} için gerekli dosyalar bulunamadı. Lütfen eğitim notebookunun çalıştığından emin olun.')\n",
    "        print(f'Eksik dosya: {e.filename}')\n",
    "\n",
    "# Sonuçları görselleştir\n",
    "if test_results:\n",
    "    results_df = pd.DataFrame(test_results)\n",
    "\n",
    "    # Doğruluk Karşılaştırması\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(x='Model', y='Accuracy', hue='Dataset', data=results_df, palette='viridis')\n",
    "    plt.title('RNN Test Verisi Üzerindeki Performans (Doğruluk)')\n",
    "    plt.ylabel('Doğruluk Oranı')\n",
    "    plt.xlabel('Model')\n",
    "    plt.legend(title='Veri Seti')\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "    # F1-Skoru Karşılaştırması\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(x='Model', y='F1-Score', hue='Dataset', data=results_df, palette='plasma')\n",
    "    plt.title('RNN Test Verisi Üzerindeki Performans (F1-Skoru)')\n",
    "    plt.ylabel('F1-Skoru (Ağırlıklı)')\n",
    "    plt.xlabel('Model')\n",
    "    plt.legend(title='Veri Seti')\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Karşılaştırılacak test sonucu bulunamadı. Lütfen eğitim notebookunun çalıştığından emin olun.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
