{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ses Tabanlı Duygu Tanıma (Speech Emotion Recognition - SER)\n",
    "Bu notebook, **CREMA-D** ve **EMO-DB** veri setlerini kullanarak ses dosyalarından duygu tanıma işlemi gerçekleştirir. RNN (LSTM) modeli kullanılır. Adımlar:\n",
    "1. **Veri Artırma**: Gürültü ekleme, hız değiştirme, perde kaydırma.\n",
    "2. **Öznitelik Çıkarma**: MFCC zaman serileri.\n",
    "3. **Veri Ön İşleme**: Eğitim/doğrulama/test bölmesi, StandardScaler ile ölçeklendirme.\n",
    "4. **Sınıf Dengesizliği (Opsiyonel)**: SMOTE ile dengeleme.\n",
    "5. **Modelleme**: LSTM tabanlı RNN modeli eğitilir ve kaydedilir.\n",
    "6. **Görselleştirme**: Sınıf dağılımı, kayıp eğrileri, karışıklık matrisi ve performans metrikleri."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gerekli Kütüphaneler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Veri Yükleme ve Öznitelik Çıkarma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path, emotion_map, dataset_name, max_per_class=50, fixed_length=32000, use_augmentation=True):\n",
    "    \"\"\"Veri setini yükler, artırır ve MFCC özniteliklerini zaman serisi olarak çıkarır.\"\"\"\n",
    "    features, labels = [], []\n",
    "    sample_rate = 22050 if dataset_name == 'CREMA-D' else 16000\n",
    "    print(f\"{dataset_name} veri seti yükleniyor... (Sample Rate: {sample_rate})\")\n",
    "    \n",
    "    for emotion_code, emotion_name in emotion_map.items():\n",
    "        path_pattern = os.path.join(dataset_path, f'*{emotion_code}*.wav')\n",
    "        files = glob.glob(path_pattern)[:max_per_class]\n",
    "        if not files:\n",
    "            print(f\"Uyarı: {emotion_code} ({emotion_name}) sınıfında dosya bulunamadı.\")\n",
    "            continue\n",
    "        print(f\"{emotion_name} sınıfı: {len(files)} dosya bulundu.\")\n",
    "        for file_name in files:\n",
    "            try:\n",
    "                y, sr = librosa.load(file_name, sr=sample_rate, res_type='kaiser_fast')\n",
    "                if len(y) == 0:\n",
    "                    print(f\"Uyarı: {file_name} boş veya hatalı.\")\n",
    "                    continue\n",
    "                # Ses uzunluğunu sabitle\n",
    "                if len(y) > fixed_length:\n",
    "                    y = y[:fixed_length]\n",
    "                else:\n",
    "                    y = np.pad(y, (0, max(0, fixed_length - len(y))), mode='constant')\n",
    "                \n",
    "                # Veri artırma\n",
    "                audios = augment_audio(y, sr, fixed_length) if use_augmentation else [y]\n",
    "                for audio in audios:\n",
    "                    # MFCC özniteliklerini çıkar (zaman serisi)\n",
    "                    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "                    features.append(mfcc.T)  # (time_steps, n_mfcc)\n",
    "                    labels.append(emotion_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Hata: {file_name} işlenemedi. Hata: {str(e)}\")\n",
    "    \n",
    "    if not features:\n",
    "        print(f\"Hata: {dataset_name} için hiç öznitelik çıkarılamadı.\")\n",
    "        return np.array([]), np.array([])\n",
    "    \n",
    "    # Zaman serilerini aynı uzunluğa getir\n",
    "    max_time_steps = max(f.shape[0] for f in features)\n",
    "    features_padded = np.array([np.pad(f, ((0, max_time_steps - f.shape[0]), (0, 0)), mode='constant') for f in features])\n",
    "    labels = np.array(labels)\n",
    "    print(f\"{dataset_name}: Toplam {len(features_padded)} örnek, Zaman adımı: {max_time_steps}\")\n",
    "    return features_padded, labels\n",
    "\n",
    "def augment_audio(y, sr, fixed_length=32000):\n",
    "    \"\"\"Ses verisini artırmak için gürültü, hız değiştirme ve perde kaydırma uygular.\"\"\"\n",
    "    augmented = []\n",
    "    y = y / np.max(np.abs(y)) if np.max(np.abs(y)) != 0 else y\n",
    "    if len(y) > fixed_length:\n",
    "        y = y[:fixed_length]\n",
    "    else:\n",
    "        y = np.pad(y, (0, fixed_length - len(y)), mode='constant')\n",
    "    augmented.append(y)\n",
    "    \n",
    "    noise = y + 0.005 * np.random.randn(len(y))\n",
    "    augmented.append(noise)\n",
    "    \n",
    "    try:\n",
    "        speed = librosa.effects.time_stretch(y, rate=1.1)\n",
    "        if len(speed) > fixed_length:\n",
    "            speed = speed[:fixed_length]\n",
    "        else:\n",
    "            speed = np.pad(speed, (0, fixed_length - len(speed)), mode='constant')\n",
    "        augmented.append(speed)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        pitch = librosa.effects.pitch_shift(y, sr=sr, n_steps=np.random.uniform(-1, 1))\n",
    "        if len(pitch) > fixed_length:\n",
    "            pitch = pitch[:fixed_length]\n",
    "        else:\n",
    "            pitch = np.pad(pitch, (0, fixed_length - len(pitch)), mode='constant')\n",
    "        augmented.append(pitch)\n",
    "    except:\n",
    "        pass\n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RNN Modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size=13, hidden_size=64, num_layers=2, num_classes=6):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.3)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Veri Seti Sınıfı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Eğitim Fonksiyonu (Görselleştirme ile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn(model, train_loader, val_loader, dataset_name, le, num_epochs=20, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    best_val_acc = 0.0\n",
    "    train_losses, val_losses = [], []\n",
    "    val_accuracies, val_f1s, val_precisions, val_recalls = [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds, val_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Performans metrikleri\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "        val_precision = precision_score(val_labels, val_preds, average='weighted')\n",
    "        val_recall = recall_score(val_labels, val_preds, average='weighted')\n",
    "        val_accuracies.append(val_acc)\n",
    "        val_f1s.append(val_f1)\n",
    "        val_precisions.append(val_precision)\n",
    "        val_recalls.append(val_recall)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Accuracy: {val_acc:.4f}')\n",
    "\n",
    "        # En iyi modeli kaydet\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), f'rnn_model_{dataset_name}.pth')\n",
    "            print(f'--> Yeni en iyi model kaydedildi (Doğruluk: {best_val_acc:.4f})')\n",
    "\n",
    "            # En iyi model için karışıklık matrisi\n",
    "            cm = confusion_matrix(val_labels, val_preds)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "            plt.title(f'RNN ({dataset_name}) En İyi Model Karışıklık Matrisi (Epoch {epoch+1})')\n",
    "            plt.xlabel('Tahmin Edilen')\n",
    "            plt.ylabel('Gerçek')\n",
    "            plt.show()\n",
    "\n",
    "    # Eğitim ve doğrulama kayıp eğrileri\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses, label='Eğitim Kaybı')\n",
    "    plt.plot(range(1, num_epochs + 1), val_losses, label='Doğrulama Kaybı')\n",
    "    plt.title(f'{dataset_name} - Eğitim ve Doğrulama Kayıp Eğrileri')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Kayıp')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Doğrulama performans metrikleri grafiği\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, num_epochs + 1), val_accuracies, label='Doğruluk')\n",
    "    plt.plot(range(1, num_epochs + 1), val_f1s, label='F1-Skoru')\n",
    "    plt.plot(range(1, num_epochs + 1), val_precisions, label='Hassasiyet')\n",
    "    plt.plot(range(1, num_epochs + 1), val_recalls, label='Duyarlılık')\n",
    "    plt.title(f'{dataset_name} - Doğrulama Performans Metrikleri')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Değer')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return train_losses, val_losses, val_accuracies, val_f1s, val_precisions, val_recalls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Veri Seti Yolları ve Duygu Haritaları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = './'\n",
    "CREMA_D_PATH = os.path.join(BASE_PATH, 'datasets/CREMA-D')\n",
    "EMODB_PATH = os.path.join(BASE_PATH, 'datasets/EMO-DB')\n",
    "\n",
    "crema_emotion_map = {\n",
    "    'HAP': 'Happy',\n",
    "    'SAD': 'Sad',\n",
    "    'ANG': 'Angry',\n",
    "    'FEA': 'Fear',\n",
    "    'DIS': 'Disgust',\n",
    "    'NEU': 'Neutral'\n",
    "}\n",
    "\n",
    "emodb_emotion_map = {\n",
    "    'angry': 'Angry',\n",
    "    'happy': 'Happy',\n",
    "    'disgusted': 'Disgust',\n",
    "    'fearful': 'Fear',\n",
    "    'surprised': 'Surprised',\n",
    "    'sad': 'Sad',\n",
    "    'neutral': 'Neutral'\n",
    "}\n",
    "\n",
    "datasets_to_process = [\n",
    "    ('CREMA-D', CREMA_D_PATH, crema_emotion_map, False),\n",
    "    ('CREMA-D_AUG', CREMA_D_PATH, crema_emotion_map, True),\n",
    "    ('EMO-DB', EMODB_PATH, emodb_emotion_map, False)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Veri Ön İşleme ve Eğitim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for dataset_name, dataset_path, emotion_map, use_augmentation in datasets_to_process:\n",
    "    print(f\"\\n{'='*20} {dataset_name} VERİ SETİ İŞLENİYOR {'='*20}\")\n",
    "    features, labels = load_data(dataset_path, emotion_map, dataset_name, max_per_class=50, use_augmentation=use_augmentation)\n",
    "    if features.size == 0:\n",
    "        print(f\"{dataset_name} veri seti atlanıyor çünkü hiç örnek yüklenemedi.\")\n",
    "        continue\n",
    "\n",
    "    # Etiketleri sayısal formata çevir\n",
    "    le = LabelEncoder()\n",
    "    labels_encoded = le.fit_transform(labels)\n",
    "    joblib.dump(le, f'label_encoder_{dataset_name}.pkl')\n",
    "\n",
    "    # Sınıf dağılımını görselleştir\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x=unique, y=counts)\n",
    "    plt.title(f\"{dataset_name} Orijinal Sınıf Dağılımı\" + (\" (Artırma Sonrası)\" if use_augmentation else \"\"))\n",
    "    plt.xlabel('Duygu')\n",
    "    plt.ylabel('Örnek Sayısı')\n",
    "    plt.show()\n",
    "\n",
    "    # Veri setini böl\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(features, labels_encoded, test_size=0.3, random_state=42, stratify=labels_encoded)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "    # Ölçeklendirme\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1)).reshape(X_train.shape)\n",
    "    X_val_scaled = scaler.transform(X_val.reshape(X_val.shape[0], -1)).reshape(X_val.shape)\n",
    "    X_test_scaled = scaler.transform(X_test.reshape(X_test.shape[0], -1)).reshape(X_test.shape)\n",
    "    joblib.dump(scaler, f'scaler_{dataset_name}.pkl')\n",
    "\n",
    "    # SMOTE (opsiyonel)\n",
    "    use_smote = False\n",
    "    if use_smote:\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], -1)\n",
    "        X_train_balanced, y_train_balanced = smote.fit_resample(X_train_reshaped, y_train)\n",
    "        X_train_balanced = X_train_balanced.reshape(-1, X_train_scaled.shape[1], X_train_scaled.shape[2])\n",
    "        print(f\"{dataset_name} - SMOTE sonrası eğitim seti boyutu: {X_train_balanced.shape}\")\n",
    "    else:\n",
    "        X_train_balanced, y_train_balanced = X_train_scaled, y_train\n",
    "\n",
    "    # Veri setlerini hazırla\n",
    "    train_dataset = AudioDataset(X_train_balanced, y_train_balanced)\n",
    "    val_dataset = AudioDataset(X_val_scaled, y_val)\n",
    "    test_dataset = AudioDataset(X_test_scaled, y_test)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "    # RNN modelini başlat\n",
    "    num_classes = len(np.unique(labels_encoded))\n",
    "    model = RNNModel(input_size=X_train_scaled.shape[2], hidden_size=64, num_layers=2, num_classes=num_classes)\n",
    "\n",
    "    # Modeli eğit\n",
    "    train_losses, val_losses, val_accuracies, val_f1s, val_precisions, val_recalls = train_rnn(\n",
    "        model, train_loader, val_loader, dataset_name, le, num_epochs=20\n",
    "    )\n",
    "\n",
    "    # Sonuçları kaydet\n",
    "    results.append({\n",
    "        'Model': ['RNN'],\n",
    "        'Accuracy': [max(val_accuracies)],\n",
    "        'F1-Score': [max(val_f1s)],\n",
    "        'Precision': [max(val_precisions)],\n",
    "        'Recall': [max(val_recalls)],\n",
    "        'Dataset': [dataset_name]\n",
    "    })\n",
    "\n",
    "    # Test verilerini kaydet\n",
    "    np.save(f'X_test_{dataset_name}.npy', X_test_scaled)\n",
    "    np.save(f'y_test_{dataset_name}.npy', y_test)\n",
    "\n",
    "# Tüm veri setlerinin performans karşılaştırması\n",
    "if results:\n",
    "    results_df = pd.concat([pd.DataFrame(r) for r in results], ignore_index=True)\n",
    "\n",
    "    # Doğruluk Karşılaştırması\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.barplot(x='Model', y='Accuracy', hue='Dataset', data=results_df, palette='viridis')\n",
    "    plt.title('RNN Model Performans Karşılaştırması (Doğruluk)')\n",
    "    plt.ylabel('Doğruluk Oranı')\n",
    "    plt.xlabel('Model')\n",
    "    plt.legend(title='Veri Seti')\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "    # F1-Skoru Karşılaştırması\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.barplot(x='Model', y='F1-Score', hue='Dataset', data=results_df, palette='plasma')\n",
    "    plt.title('RNN Model Performans Karşılaştırması (F1-Skoru)')\n",
    "    plt.ylabel('F1-Skoru (Ağırlıklı)')\n",
    "    plt.xlabel('Model')\n",
    "    plt.legend(title='Veri Seti')\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "    # Hassasiyet (Precision) Karşılaştırması\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.barplot(x='Model', y='Precision', hue='Dataset', data=results_df, palette='magma')\n",
    "    plt.title('RNN Model Performans Karşılaştırması (Hassasiyet)')\n",
    "    plt.ylabel('Hassasiyet (Ağırlıklı)')\n",
    "    plt.xlabel('Model')\n",
    "    plt.legend(title='Veri Seti')\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "    # Duyarlılık (Recall) Karşılaştırması\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.barplot(x='Model', y='Recall', hue='Dataset', data=results_df, palette='inferno')\n",
    "    plt.title('RNN Model Performans Karşılaştırması (Duyarlılık)')\n",
    "    plt.ylabel('Duyarlılık (Ağırlıklı)')\n",
    "    plt.xlabel('Model')\n",
    "    plt.legend(title='Veri Seti')\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Karşılaştırılacak sonuç bulunamadı.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
